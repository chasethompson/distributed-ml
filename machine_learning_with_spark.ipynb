{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydataset import data\n",
    "import pyspark\n",
    "import pyspark.ml\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "\n",
    "df = spark.createDataFrame(data('tips'))\n",
    "\n",
    "train, test = df.randomSplit([0.8, 0.2], 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape(df: pyspark.sql.DataFrame):\n",
    "    return df.count(), len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 7)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 7)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first demonstrate a regression problem: predicting the tip amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.29| 2.6|Female|    No|Sun|Dinner|   2|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyspark.ml.feature.RFormula\n",
    "\n",
    "- tip ~ total_bill: predict tip based on total bill\n",
    "- tip ~ total_bill + size: predict tip based on total bill and size\n",
    "- tip ~ .: predict tip based on all the other features in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|   features|label|\n",
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2| [8.77,2.0]|  2.0|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|[10.27,2.0]| 1.71|\n",
      "|     10.29| 2.6|Female|    No|Sun|Dinner|   2|[10.29,2.0]|  2.6|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|[10.33,3.0]| 1.67|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|[10.34,3.0]| 1.66|\n",
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# nb: spark's rformula does encoding\n",
    "rf = pyspark.ml.feature.RFormula(formula=\"tip ~ total_bill + size\").fit(train)\n",
    "\n",
    "rf.transform(train).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features and labels columns are the shape/name required for pyspark.ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|   features|label|\n",
      "+-----------+-----+\n",
      "| [8.77,2.0]|  2.0|\n",
      "|[10.27,2.0]| 1.71|\n",
      "|[10.29,2.0]|  2.6|\n",
      "|[10.33,3.0]| 1.67|\n",
      "|[10.34,3.0]| 1.66|\n",
      "+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_input = rf.transform(train).select('features', 'label')\n",
    "train_input.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create, fit, and use the model.\n",
    "\n",
    "**Note**: unlike sklearn, each step produces a new object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression_5e14d2861a13"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = pyspark.ml.regression.LinearRegression()\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(lr.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+------------------+\n",
      "|   features|label|        prediction|\n",
      "+-----------+-----+------------------+\n",
      "| [8.77,2.0]|  2.0|1.8431748565237704|\n",
      "|[10.27,2.0]| 1.71|1.9846902983830197|\n",
      "|[10.29,2.0]|  2.6|1.9865771709411428|\n",
      "|[10.33,3.0]| 1.67| 2.151932135488475|\n",
      "|[10.34,3.0]| 1.66|2.1528755717675363|\n",
      "+-----------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_fit = lr.fit(train_input)\n",
    "lr_fit.transform(train_input).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.ml.regression.LinearRegressionTrainingSummary at 0x7feb21a7e250>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_fit.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5083641431094579, 0.925413890798643)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_fit.summary.r2, lr_fit.summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coefficientStandardErrors',\n",
       " 'degreesOfFreedom',\n",
       " 'devianceResiduals',\n",
       " 'explainedVariance',\n",
       " 'featuresCol',\n",
       " 'labelCol',\n",
       " 'meanAbsoluteError',\n",
       " 'meanSquaredError',\n",
       " 'numInstances',\n",
       " 'objectiveHistory',\n",
       " 'pValues',\n",
       " 'predictionCol',\n",
       " 'predictions',\n",
       " 'r2',\n",
       " 'r2adj',\n",
       " 'residuals',\n",
       " 'rootMeanSquaredError',\n",
       " 'tValues',\n",
       " 'totalIterations']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(lr_fit.summary) if not x.startswith('_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we do on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+------+---+------+----+-----------+-----+------------------+\n",
      "|total_bill| tip| sex|smoker|day|  time|size|   features|label|        prediction|\n",
      "+----------+----+----+------+---+------+----+-----------+-----+------------------+\n",
      "|      9.55|1.45|Male|    No|Sat|Dinner|   2| [9.55,2.0]| 1.45|1.9167628862905801|\n",
      "|      9.68|1.32|Male|    No|Sun|Dinner|   2| [9.68,2.0]| 1.32|1.9290275579183815|\n",
      "|      9.94|1.56|Male|    No|Sun|Dinner|   2| [9.94,2.0]| 1.56|1.9535569011739848|\n",
      "|     11.24|1.76|Male|   Yes|Sat|Dinner|   2|[11.24,2.0]| 1.76| 2.076203617452001|\n",
      "+----------+----+----+------+---+------+----+-----------+-----+------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_input = rf.transform(test)\n",
    "lr_fit.transform(test_input).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2722254530718242"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = pyspark.ml.evaluation.RegressionEvaluator()\n",
    "rmse = evaluator.evaluate(lr_fit.transform(test_input))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Predict time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.29| 2.6|Female|    No|Sun|Dinner|   2|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|   features|label|\n",
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2| [8.77,2.0]|  0.0|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|[10.27,2.0]|  0.0|\n",
      "|     10.29| 2.6|Female|    No|Sun|Dinner|   2|[10.29,2.0]|  0.0|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|[10.33,3.0]|  0.0|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|[10.34,3.0]|  0.0|\n",
      "|     12.54| 2.5|  Male|    No|Sun|Dinner|   2|[12.54,2.0]|  0.0|\n",
      "|     13.37| 2.0|  Male|    No|Sat|Dinner|   2|[13.37,2.0]|  0.0|\n",
      "|     13.94|3.06|  Male|    No|Sun|Dinner|   2|[13.94,2.0]|  0.0|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|[14.78,2.0]|  0.0|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|[14.83,2.0]|  0.0|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|[15.04,2.0]|  0.0|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|[15.42,2.0]|  0.0|\n",
      "|     15.77|2.23|Female|    No|Sat|Dinner|   2|[15.77,2.0]|  0.0|\n",
      "|     16.04|2.24|  Male|    No|Sat|Dinner|   3|[16.04,3.0]|  0.0|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|[16.29,3.0]|  0.0|\n",
      "|     16.31| 2.0|  Male|    No|Sat|Dinner|   3|[16.31,3.0]|  0.0|\n",
      "|     16.93|3.07|Female|    No|Sat|Dinner|   3|[16.93,3.0]|  0.0|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|[16.97,3.0]|  0.0|\n",
      "|     17.46|2.54|  Male|    No|Sun|Dinner|   2|[17.46,2.0]|  0.0|\n",
      "|     17.78|3.27|  Male|    No|Sat|Dinner|   2|[17.78,2.0]|  0.0|\n",
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = pyspark.ml.feature.RFormula(formula='time ~ total_bill + size').fit(train)\n",
    "train_input = rf.transform(train)\n",
    "train_input.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = pyspark.ml.classification.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(lr.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_fit = lr.fit(train_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'areaUnderROC',\n",
       " 'fMeasureByLabel',\n",
       " 'fMeasureByThreshold',\n",
       " 'falsePositiveRateByLabel',\n",
       " 'featuresCol',\n",
       " 'labelCol',\n",
       " 'labels',\n",
       " 'objectiveHistory',\n",
       " 'pr',\n",
       " 'precisionByLabel',\n",
       " 'precisionByThreshold',\n",
       " 'predictionCol',\n",
       " 'predictions',\n",
       " 'probabilityCol',\n",
       " 'recallByLabel',\n",
       " 'recallByThreshold',\n",
       " 'roc',\n",
       " 'totalIterations',\n",
       " 'truePositiveRateByLabel',\n",
       " 'weightedFMeasure',\n",
       " 'weightedFalsePositiveRate',\n",
       " 'weightedPrecision',\n",
       " 'weightedRecall',\n",
       " 'weightedTruePositiveRate']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(lr_fit.summary) if not x.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6430830039525692"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# area under TPR (recall) vs FPR (FP / (FP + TN)) curve\n",
    "# https://en.wikipedia.org/wiki/Receiver_operating_characteristic\n",
    "lr_fit.summary.areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5809716599190283"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = pyspark.ml.evaluation.BinaryClassificationEvaluator()\n",
    "test_auc = evaluator.evaluate(lr_fit.transform(rf.transform(test)))\n",
    "test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = rf.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+---+\n",
      "|prediction|0.0|1.0|\n",
      "+----------+---+---+\n",
      "|       0.0| 38| 13|\n",
      "+----------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for the test data\n",
    "(lr_fit.transform(test_input)\n",
    " .select('time', 'total_bill', 'size', 'label', 'probability', 'prediction')\n",
    " .groupby('prediction') # predicted == rows\n",
    " .pivot('label') # actual values are columns\n",
    " .count()\n",
    " .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many other preprocessing steps\n",
    "# dir(pyspark.ml.feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
